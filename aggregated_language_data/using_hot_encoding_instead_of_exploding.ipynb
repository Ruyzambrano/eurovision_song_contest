{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import mafese\n",
    "from mafese.wrapper.mha import MhaSelector\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.metrics import root_mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import altair as alt\n",
    "\n",
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/combined_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format the Languages to be a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Language\"] = data[\"Language\"].str.removeprefix(\"[\").str.removesuffix(\"]\").str.split(\",\")\n",
    "data['Language'] = data['Language'].apply(lambda languages: [lang.strip().strip(\"'\\\" \") for lang in languages])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode the Languages as Binaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "language_encoded = mlb.fit_transform(data['Language'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_df = pd.DataFrame(language_encoded, columns=mlb.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([data, language_df], axis=1).drop(columns=['Language'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform for ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['Country Name', \"Country Code\", \"Song\", \"Artist\"]\n",
    "numeric_cols = data.columns.difference(categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[numeric_cols] = data[numeric_cols].fillna(data[numeric_cols].median())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_columns = data.columns[data.isnull().all()]\n",
    "data = data.drop(columns=empty_columns).drop(columns=[\"Song\", \"Country Code\", \"Year\", \"Grand Final Points\", \"Semifinal\", \"Artist\", \"Semifinal Points\", \"Semifinal Place\", \"index\", \"level_0\", \"Unnamed: 0\"])\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_cols = gb_importance_df[\"Feature\"].head(50).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_encoded = pd.get_dummies(data, columns=[\"Country Name\"], drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = data_encoded[\"Grand Final Place\"].values\n",
    "# non_targets = data_encoded[selected_cols].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data_encoded[\"Grand Final Place\"].values\n",
    "non_targets = data_encoded.drop(columns=[\"Grand Final Place\"]).values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform using Mafese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mafese.Data(non_targets, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.split_train_test(test_size=0.2, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df = pd.DataFrame(data.X_train)\n",
    "X_test_df = pd.DataFrame(data.X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_scaler = StandardScaler()\n",
    "\n",
    "data.X_train = standard_scaler.fit_transform(data.X_train)\n",
    "data.X_test = standard_scaler.transform(data.X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.y_train, scaler_y = data.encode_label(data.y_train)\n",
    "data.y_test = scaler_y.transform(data.y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_selector = MhaSelector(problem=\"regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [0.9, 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_selector.fit(data.X_train, data.y_train, fit_weights=weights, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_selected = feat_selector.transform(data.X_train)\n",
    "X_test_selected = feat_selector.transform(data.X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_classes, class_counts = np.unique(data.y_train, return_counts=True)\n",
    "print(\"Unique classes in y_train:\", unique_classes)\n",
    "print(\"Counts of each class in y_train:\", class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_selector.selected_feature_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_feature_indices = feat_selector.selected_feature_indexes\n",
    "feature_names = data_encoded.drop(columns=[\"Grand Final Place\"]).columns.values\n",
    "selected_features = feature_names[selected_feature_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_model = GradientBoostingRegressor(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_gb = GridSearchCV(gb_model, gb_param_grid, cv=5, verbose=2, n_jobs=-1, scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_gb.fit(X_train_selected, data.y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_gb = grid_search_gb.best_params_\n",
    "best_gb_model = grid_search_gb.best_estimator_\n",
    "print(\"Best parameters: \", best_params_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_model = GradientBoostingRegressor(**best_params_gb)\n",
    "gb_model.fit(X_train_selected, data.y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_importances = gb_model.feature_importances_\n",
    "gb_importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names[selected_feature_indices],\n",
    "    'Importance': gb_importances\n",
    "}).sort_values(by='Importance', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nGradient Boosting - Feature Importances:\")\n",
    "gb_importance_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(gb_importance_df.head(10)).mark_bar().encode(\n",
    "    x=alt.X('Importance:Q', title='Importance'),\n",
    "    y=alt.Y('Feature:N', sort='-x', title=None),\n",
    "    color=\"Importance\"\n",
    ").properties(\n",
    "    title='Top 10 Feature Importances - Gradient Boosting',\n",
    "    width=1000,\n",
    "    height=400\n",
    ").configure_axisY(\n",
    "    labelAngle=-25,  # Align text horizontally\n",
    "    labelLimit=500,  # Maximum allowed pixel width of a label\n",
    "    labelAlign='right'  # Align labels to the left\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_gb = best_gb_model.predict(X_test_selected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rmse_gb = root_mean_squared_error(data.y_test, y_pred_gb)\n",
    "test_mae_gb = mean_absolute_error(data.y_test, y_pred_gb)\n",
    "test_r2_gb = r2_score(data.y_test, y_pred_gb)\n",
    "\n",
    "\n",
    "print(\"Test RMSE: \", test_rmse_gb)\n",
    "print(\"Test MAE: \", test_mae_gb)\n",
    "print(\"Test R²: \", test_r2_gb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_model = GradientBoostingRegressor(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'colsample_bytree': [0.3, 0.7]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_xgb = GridSearchCV(xgb_model, xgb_param_grid, cv=5, verbose=2, n_jobs=-1, scoring='neg_mean_squared_error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_xgb.fit(X_train_selected, data.y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_xgb = grid_search_xgb.best_params_\n",
    "best_xgb_model = grid_search_xgb.best_estimator_\n",
    "print(\"Best parameters: \", best_params_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_gb_model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = best_xgb_model\n",
    "xgb_importances = best_xgb_model.feature_importances_\n",
    "xgb_importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names[selected_feature_indices],\n",
    "    'Importance': xgb_importances\n",
    "}).sort_values(by='Importance', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_importance_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(xgb_importance_df.head(10)).mark_bar().encode(\n",
    "    x=alt.X('Importance:Q', title='Importance'),\n",
    "    y=alt.Y('Feature:N', sort='-x', title=None),\n",
    "    color=\"Importance\"\n",
    ").properties(\n",
    "    title='Top 10 Feature Importances - Gradient Boosting',\n",
    "    width=1000,\n",
    "    height=400\n",
    ").configure_axisY(\n",
    "    labelAngle=-25,  # Align text horizontally\n",
    "    labelLimit=500,  # Maximum allowed pixel width of a label\n",
    "    labelAlign='right'  # Align labels to the left\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xgb = best_xgb_model.predict(X_test_selected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rmse_xgb = root_mean_squared_error(data.y_test, y_pred_xgb)\n",
    "test_mae_xgb = mean_absolute_error(data.y_test, y_pred_xgb)\n",
    "test_r2_xgb = r2_score(data.y_test, y_pred_xgb)\n",
    "\n",
    "\n",
    "print(\"Test RMSE: \", test_rmse_xgb)\n",
    "print(\"Test MAE: \", test_mae_xgb)\n",
    "print(\"Test R²: \", test_r2_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=(data.X_train.shape[1],)))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(data.X_train, data.y_train, epochs=100, batch_size=32, validation_split=0.2, verbose=1, callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_scores = cross_val_score(GradientBoostingRegressor(**best_params_gb), data.X_train, data.y_train, cv=kf, scoring='r2')\n",
    "print(\"Cross-validated R² scores for Gradient Boosting:\", np.mean(r2_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dnn = model.predict(data.X_test)\n",
    "rmse_dnn = root_mean_squared_error(data.y_test, y_pred_dnn)\n",
    "mae_dnn = mean_absolute_error(data.y_test, y_pred_dnn)\n",
    "r2_dnn = r2_score(data.y_test, y_pred_dnn)\n",
    "\n",
    "print(\"Test RMSE:\", rmse_dnn)\n",
    "print(\"Test MAE:\", mae_dnn)\n",
    "print(\"Test R²:\", r2_dnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise the DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['mae'], label='Training MAE')\n",
    "plt.plot(history.history['val_mae'], label='Validation MAE')\n",
    "plt.title('Model MAE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Mean Absolute Error')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = feat_selector.evaluate(estimator=SVR(), data=data, metrics=[\"RMSE\", \"MAE\", \"MAPE\", \"R2\", \"NSE\", \"KGE\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = f\"\"\"\n",
    "Run at: {datetime.now()}\n",
    "Weights = {weights}\n",
    "Outputs:\n",
    "\"\"\"\n",
    "for key in results.keys():\n",
    "    output += f\"\\t{key}: {results[key]}\\n\"\n",
    "\n",
    "output += f\"\"\"Gradient Boosting\n",
    "\\tTest RMSE: {test_rmse_gb}\n",
    "\\tTest MAE: {test_mae_gb}\n",
    "\\tTest R²: {test_r2_gb}\n",
    "\\tBest parameters: \n",
    "\"\"\"\n",
    "for key in best_params_gb.keys():\n",
    "    output += f\"\\t{key}: {best_params_gb[key]}\\n\"\n",
    "\n",
    "output += f\"\"\"XGBoost\n",
    "\\tTest RMSE: {test_rmse_xgb}\n",
    "\\tTest MAE: {test_mae_xgb}\n",
    "\\tTest R²: {test_r2_xgb}\n",
    "\\tBest parameters: \n",
    "\"\"\"\n",
    "for key in best_params_xgb.keys():\n",
    "    output += f\"\\t{key}: {best_params_xgb[key]}\\n\"\n",
    "\n",
    "output += f\"\"\"Deep Neural Network\n",
    "\\tTest RMSE: {rmse_dnn}\n",
    "\\tTest MAE: {mae_dnn}\n",
    "\\tTest R²: {r2_dnn}\n",
    "\"\"\"\n",
    "\n",
    "with open(\"outputs/outputs.txt\", \"a\", encoding=\"UTF-8\") as f:\n",
    "    f.write(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
