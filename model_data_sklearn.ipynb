{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = pd.read_csv(\"./data/combined_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data[\"Grand Final Place\"] = combined_data[\"Grand Final Place\"].fillna(27+combined_data[\"Semifinal Points\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data.columns[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = combined_data.drop(\n",
    "    ['Country Name',\n",
    "     'Country Code', \n",
    "     'Year', \n",
    "     'Grand Final Place', \n",
    "     \"Song\", \n",
    "     \"Artist\", \n",
    "     \"Grand Final Points\", \n",
    "     \"Semifinal\",\n",
    "     \"Semifinal Points\",\n",
    "     \"Semifinal Place\",\n",
    "     \"Language\",\n",
    "     \"index\",\n",
    "     \"Use of insecticide-treated bed nets (% of under-5 population)\"\n",
    "     ], \n",
    "     axis=1)\n",
    "target = combined_data['Grand Final Place']\n",
    "numeric_features.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = combined_data[['Country Name', 'Language']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "encoded_categorical_features = encoder.fit_transform(categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_categorical_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = encoder.get_feature_names_out(categorical_features.columns)\n",
    "len(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_categorical_df = pd.DataFrame(encoded_categorical_features, columns=feature_names)\n",
    "encoded_categorical_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = pd.concat([numeric_features, encoded_categorical_df], axis=1)\n",
    "numeric_features.sample(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy='median')\n",
    "numeric_features = pd.DataFrame(imputer.fit_transform(numeric_features), columns=numeric_features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in numeric_features.columns:\n",
    "    if numeric_features[col].isna().sum() != 0:\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_features = pd.concat([numeric_features, encoded_categorical_df], axis=1)\n",
    "final_data = pd.concat([final_features, combined_data['Grand Final Place'].reset_index(drop=True)], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = final_data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_correlation = correlation_matrix['Grand Final Place']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_correlation_sorted = target_correlation.abs().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_features = target_correlation_sorted.index[1:21] \n",
    "print(\"Top features correlated with the target variable:\\n\", target_correlation_sorted.head(21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_features_top = final_data[top_features]\n",
    "final_features.sample(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_top = final_data['Grand Final Place']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(final_features, target, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(random_state=42)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f'Root Mean Squared Error: {rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, n_jobs=-1, scoring='neg_mean_squared_error', verbose=2)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid_search.best_params_\n",
    "best_score = np.sqrt(-grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores = cross_val_score(rf, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "cv_rmse_scores = np.sqrt(-cv_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Best Parameters: {best_params}')\n",
    "print(f'Best RMSE via GridSearchCV: {best_score}')\n",
    "print(f'Root Mean Squared Error with Best Model: {rmse}')\n",
    "print(f'Cross-Validation RMSE scores: {cv_rmse_scores}')\n",
    "print(f'Average Cross-Validation RMSE: {cv_rmse_scores.mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"logs/model_outputs.txt\", \"a\", encoding=\"UTF-8\") as f:\n",
    "    f.write(f\"\"\"Run at {datetime.now()}:\n",
    "Best Parameters: {best_params}\n",
    "Best RMSE via GridSearchCV: {best_score}\n",
    "Root Mean Squared Error with Best Model: {rmse}\n",
    "Cross-Validation RMSE scores: {cv_rmse_scores}\n",
    "Average Cross-Validation RMSE: {cv_rmse_scores.mean()}\"\"\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
